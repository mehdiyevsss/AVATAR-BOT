<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Voice Avatar Chatbot</title>
  <style>
    * { box-sizing: border-box; }
    html, body {
      margin: 0; padding: 0;
      height: 100vh; width: 100vw;
      font-family: "Segoe UI", sans-serif;
      background: #574e4e; color: #2D3439;
      display: flex; justify-content: center; align-items: center;
    }
    .container {
      display: flex;
      height: 90vh; width: 90vw; max-width: 1400px;
      border-radius: 16px; background: #fff;
      box-shadow: 0 2px 8px rgba(225, 228, 232, 0.5);
      overflow: hidden;
    }
    model-viewer {
      flex: 1 1 0; height: 100%;
      background: url('/static/Swisscom.jpg') center center / cover no-repeat;
      background-color: #000;
    }
    .chat-section {
      flex: 1 1 0; display: flex; flex-direction: column;
      padding: 20px; background: #f5f5f5; height: 100%;
    }
    .messages {
      flex: 1; overflow-y: auto; margin-bottom: 15px;
      padding-right: 10px; display: flex; flex-direction: column;
    }
    .message {
      margin-bottom: 10px; padding: 14px 18px; border-radius: 14px;
      font-size: 15px; max-width: 100%; background: #e0e0e0; color: #000;
    }
    .assistant { align-self: flex-start; background-color: #dbe4ff; }
    .user { align-self: flex-end; background-color: #ffe2e2; }
    .system {
      align-self: center; background-color: #fff3cd; color: #856404;
      text-align: center;
    }
    .controls {
      display: flex; gap: 10px; flex-wrap: wrap;
    }
    .record-btn, .human-btn {
      padding: 14px; font-size: 16px;
      border-radius: 10px; border: none; cursor: pointer;
      display: flex; align-items: center; justify-content: center;
      flex: 1; min-width: 120px;
    }
    .record-btn { background: #333; color: white; }
    .human-btn { background: #28a745; color: white; display: none; }
    .video-container {
      display: none; position: fixed; top: 0; left: 0;
      width: 100%; height: 100%; background: rgba(0,0,0,0.9);
      z-index: 1000; flex-direction: column; align-items: center; justify-content: center;
    }
    .video-container.active { display: flex; }
    .video-grid { display: flex; gap: 20px; margin-bottom: 20px; }
    .video-box { background: #333; border-radius: 10px; overflow: hidden; position: relative; }
    .local-video { width: 300px; height: 225px; }
    .remote-video { width: 600px; height: 450px; }
    .video-box video { width: 100%; height: 100%; object-fit: cover; }
    .video-label {
      position: absolute; bottom: 10px; left: 10px;
      background: rgba(0, 0, 0, 0.7); color: white;
      padding: 5px 10px; border-radius: 5px; font-size: 12px;
    }
    .video-controls { display: flex; gap: 10px; }
    .video-controls button {
      padding: 12px 20px; border: none; border-radius: 8px;
      cursor: pointer; font-size: 14px; transition: background 0.3s;
    }
    .end-call { background: #dc3545; color: white; }
    .toggle-video, .toggle-audio { background: #6c757d; color: white; }
    .connection-status {
      margin-bottom: 10px; padding: 10px;
      border-radius: 5px; text-align: center; font-weight: bold;
    }
    .connecting { background: #fff3cd; color: #856404; }
    .connected { background: #d4edda; color: #155724; }
    .disconnected { background: #f8d7da; color: #721c24; }
  </style>
</head>
<body>
  <div class="container">
    <model-viewer id="avatar" src="/static/avatar2.glb" auto-rotate camera-controls></model-viewer>
    <div class="chat-section">
      <div class="messages" id="messages"></div>
      <div class="controls">
        <button id="recordBtn" class="record-btn">üéôÔ∏è Record</button>
        <button id="humanBtn" class="human-btn">üë• Connect to Human</button>
      </div>
    </div>
  </div>
  <div class="video-container" id="videoContainer">
    <div class="connection-status" id="connectionStatus">Connecting to operator...</div>
    <div class="video-grid">
      <div class="video-box local-video">
        <video id="localVideo" autoplay muted></video>
        <div class="video-label">You</div>
      </div>
      <div class="video-box remote-video">
        <video id="remoteVideo" autoplay></video>
        <div class="video-label">Operator</div>
      </div>
    </div>
    <div class="video-controls">
      <button id="toggleVideo" class="toggle-video">üìπ Video On</button>
      <button id="toggleAudio" class="toggle-audio">üé§ Audio On</button>
      <button id="endCall" class="end-call">üìû End Call</button>
    </div>
  </div>
  <script type="module" src="https://unpkg.com/@google/model-viewer/dist/model-viewer.min.js"></script>
  <script>
    const recordBtn = document.getElementById("recordBtn");
    const humanBtn = document.getElementById("humanBtn");
    const messagesEl = document.getElementById("messages");
    const avatar = document.querySelector("#avatar");
    const videoContainer = document.getElementById("videoContainer");
    const connectionStatus = document.getElementById("connectionStatus");
    const localVideo = document.getElementById("localVideo");
    const remoteVideo = document.getElementById("remoteVideo");
    const toggleVideoBtn = document.getElementById("toggleVideo");
    const toggleAudioBtn = document.getElementById("toggleAudio");
    const endCallBtn = document.getElementById("endCall");

    let currentAudio = null;
    let mediaRecorder;
    let listening = false;
    let mouthMesh, audioCtx, analyser, dataArray;
    let peerConnection, signalingSocket;
    let isVideoEnabled = true, isAudioEnabled = true;

    recordBtn.onclick = () => startListening();
    humanBtn.onclick = () => videoContainer.classList.add("active");

    // =========== LIP-SYNC SETUP ===========
    function setupMouthMesh() {
      if (!avatar) return;
      avatar.traverse(child => {
        if (child.isMesh && child.morphTargetDictionary) {
          const morphs = child.morphTargetDictionary;
          const names = Object.keys(morphs);
          let key = names.find(n => /mouth|open|viseme_aa/i.test(n));
          if (!key) {
            console.warn("No usable morph target found, using first:", names[0]);
            key = names[0];
          }
          mouthMesh = child;
          openIndex = morphs[key];
          console.log(`‚úÖ Using ${child.name} with morph "${key}" at index ${openIndex}`);
        }
      });
    }

    function startLipSync(audio) {
      if (!mouthMesh) return;

      const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
      const src = audioCtx.createMediaElementSource(audio);
      const analyser = audioCtx.createAnalyser();
      analyser.fftSize = 128;
      src.connect(analyser);
      analyser.connect(audioCtx.destination);

      const data = new Uint8Array(analyser.fftSize);
      (function animateMouth() {
        analyser.getByteTimeDomainData(data);
        let sum = 0;
        for (let v of data) {
          const n = (v / 128) - 1;
          sum += n * n;
        }
        const rms = Math.sqrt(sum / data.length);

        mouthMesh.morphTargetInfluences[openIndex] = Math.min(rms * 2, 1);

        requestAnimationFrame(animateMouth);
      })();
    }

    // =========== RECORD/TRANSCRIBE ===========
    async function startListening() {
      if (listening) return;
      listening = true;
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const audioCtx = new AudioContext();
      const micSource = audioCtx.createMediaStreamSource(stream);
      const analyser = audioCtx.createAnalyser();
      micSource.connect(analyser);
      const data = new Uint8Array(analyser.fftSize);

      mediaRecorder = new MediaRecorder(stream);
      let audioChunks = [];
      mediaRecorder.ondataavailable = e => audioChunks.push(e.data);
      mediaRecorder.onstop = () => {
        const blob = new Blob(audioChunks, { type: "audio/mp3" });
        processRecording(blob).then(() => {
          listening = false;
          startListening();
        });
      };
      audioChunks = [];
      mediaRecorder.start();
      detectSilence(analyser, data);
    }

    function detectSilence(analyser, data, timeout = 1200, threshold = 10) {
      let lastSound = Date.now();
      (function loop() {
        analyser.getByteTimeDomainData(data);
        const silent = data.every(v => Math.abs(v - 128) < threshold);
        if (!silent) lastSound = Date.now();
        if (Date.now() - lastSound > timeout && mediaRecorder.state === "recording") {
          mediaRecorder.stop();
        } else if (mediaRecorder.state === "recording") {
          requestAnimationFrame(loop);
        }
      })();
    }

    async function processRecording(blob) {
      const formData = new FormData();
      formData.append("audio", blob, "voice.mp3");
      const trans = await fetch("/transcribe", { method: "POST", body: formData }).then(r => r.json()).catch(() => null);
      if (!trans || !trans.transcript) return;
      addMessage("user", trans.transcript);

      const respForm = new FormData();
      respForm.append("text", trans.transcript);
      const resp = await fetch("/respond", { method: "POST", body: respForm }).then(r => r.json()).catch(() => null);
      if (!resp || !resp.response) return addMessage("system", "‚ö†Ô∏è Bot failed to respond.");
      addMessage("assistant", resp.response);

      if (resp.needs_human_operator) humanBtn.style.display = "block";
      if (currentAudio) currentAudio.pause();
      currentAudio = new Audio(resp.audio_url);
      currentAudio.play();
      startLipSync(currentAudio);
    }

    // =========== VIDEO CALL SETUP ===========
    function setupVideoCall() {
      videoContainer.classList.add("active");
      connectionStatus.className = "connection-status connecting";
      connectionStatus.textContent = "Connecting to operator...";

      signalingSocket = new WebSocket("wss://your-signaling-server.com");
      signalingSocket.onopen = () => {
        signalingSocket.send(JSON.stringify({ type: "connect" }));
      };

      signalingSocket.onmessage = async (event) => {
        const message = JSON.parse(event.data);
        if (message.type === "offer") {
          await setupPeerConnection();
          await peerConnection.setRemoteDescription(new RTCSessionDescription(message));
          const answer = await peerConnection.createAnswer();
          await peerConnection.setLocalDescription(answer);
          signalingSocket.send(JSON.stringify({ type: "answer", answer }));
        } else if (message.type === "iceCandidate") {
          await peerConnection.addIceCandidate(new RTCIceCandidate(message.candidate));
        }
      };

      signalingSocket.onerror = (e) => {
        console.error(e);
        connectionStatus.textContent = "Connection error";
        connectionStatus.className = "connection-status disconnected";
      };

      signalingSocket.onclose = () => {
        if (videoContainer.classList.contains("active")) {
          connectionStatus.textContent = "Connection lost";
          connectionStatus.className = "connection-status disconnected";
        }
      };
    }

    async function setupPeerConnection() {
      const configuration = { iceServers: [{ urls: "stun:stun.l.google.com:19302" }] };
      peerConnection = new RTCPeerConnection(configuration);

      const localStream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
      localVideo.srcObject = localStream;
      localStream.getTracks().forEach(track => peerConnection.addTrack(track, localStream));

      peerConnection.ontrack = (event) => {
        remoteVideo.srcObject = event.streams[0];
      };

      peerConnection.onicecandidate = (event) => {
        if (event.candidate) {
          signalingSocket.send(JSON.stringify({ type: "iceCandidate", candidate: event.candidate }));
        }
      };
    }

    // ====== VIDEO CONTROLS ======
    toggleVideoBtn.onclick = () => {
      isVideoEnabled = !isVideoEnabled;
      localStream.getVideoTracks().forEach(t => t.enabled = isVideoEnabled);
      toggleVideoBtn.textContent = isVideoEnabled ? "üìπ Video On" : "üìπ Video Off";
    };

    toggleAudioBtn.onclick = () => {
      isAudioEnabled = !isAudioEnabled;
      localStream.getAudioTracks().forEach(t => t.enabled = isAudioEnabled);
      toggleAudioBtn.textContent = isAudioEnabled ? "üé§ Audio On" : "üé§ Audio Off";
    };

    endCallBtn.onclick = endVideoCall;

    function endVideoCall() {
      if (peerConnection) {
        peerConnection.close();
        peerConnection = null;
      }
      if (signalingSocket && signalingSocket.readyState === WebSocket.OPEN) {
        signalingSocket.send(JSON.stringify({ type: "disconnect" }));
        signalingSocket.close();
      }
      if (localStream) {
        localStream.getTracks().forEach(t => t.stop());
        localStream = null;
      }
      videoContainer.classList.remove("active");
      humanBtn.style.display = "none";
      addMessage("system", "Video call ended. You can continue chatting.");
    }

    // ====== CLEANUP ON UNLOAD ======
    window.addEventListener("beforeunload", () => {
      if (peerConnection || signalingSocket) endVideoCall();
    });

    function addMessage(role, text) {
      const div = document.createElement("div");
      div.className = `message ${role}`;
      div.textContent = text;
      messagesEl.appendChild(div);
      messagesEl.scrollTop = messagesEl.scrollHeight;
    }

  recordBtn.onclick = () => startListening();

  async function startListening() {
    const socket = new WebSocket("ws://localhost:8000/ws/audio");

    socket.onmessage = async (event) => {
      const data = JSON.parse(event.data);
      if (data.transcript) {
        addMessage("user", data.transcript);
        addMessage("assistant", data.response);

        if (data.audio_url) {
          if (currentAudio) currentAudio.pause();
          currentAudio = new Audio(data.audio_url);
          currentAudio.play();
        }

        if (data.response.toLowerCase().includes("connect you with a human")) {
          humanBtn.style.display = "block";
        }
      }
    };

    socket.onopen = async () => {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const recorder = new MediaRecorder(stream, { mimeType: 'audio/webm' });

      recorder.ondataavailable = (e) => {
        if (e.data.size > 0 && socket.readyState === WebSocket.OPEN) {
          e.data.arrayBuffer().then(buf => socket.send(buf));
        }
      };

      recorder.start(250);
    };
  }

  function addMessage(role, text) {
    const div = document.createElement("div");
    div.className = `message ${role}`;
    div.textContent = text;
    messagesEl.appendChild(div);
    messagesEl.scrollTop = messagesEl.scrollHeight;
  }

  </script>
</body>
</html>
