<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <title>Voice Avatar Chatbot</title>
  <style>
    * {
      box-sizing: border-box;
    }

    html,
    body {
      margin: 0;
      padding: 0;
      height: 100vh;
      width: 100vw;
      font-family: "Segoe UI", sans-serif;
      background: #1e1e1e;
      display: flex;
      justify-content: center;
      align-items: center;
    }

    .container {
      display: flex;
      height: 90vh;
      width: 90vw;
      max-width: 1400px;
      border-radius: 16px;
      background: #fff;
      box-shadow: 0 0 20px rgba(0, 0, 0, 0.25);
      overflow: hidden;
    }

    model-viewer {
      flex: 1 1 0;
      height: 100%;
      background-color: #000;
    }

    .chat-section {
      flex: 1 1 0;
      display: flex;
      flex-direction: column;
      padding: 20px;
      background: #f5f5f5;
      height: 100%;
    }

    .messages {
      flex: 1;
      overflow-y: auto;
      margin-bottom: 15px;
      padding-right: 10px;
      display: flex;
      flex-direction: column;
    }

    .message {
      margin-bottom: 10px;
      padding: 14px 18px;
      border-radius: 14px;
      font-size: 15px;
      max-width: 100%;
      background: #e0e0e0;
      color: #000;
    }

    .assistant {
      align-self: flex-start;
      background-color: #dbe4ff;
    }

    .user {
      align-self: flex-end;
      background-color: #ffe2e2;
    }

    .system {
      align-self: center;
      background-color: #fff3cd;
      color: #856404;
      text-align: center;
    }

    .controls {
      display: flex;
      gap: 10px;
      flex-wrap: wrap;
    }

    .record-btn,
    .human-btn,
    .video-btn {
      padding: 14px;
      font-size: 16px;
      border-radius: 10px;
      border: none;
      cursor: pointer;
      transition: background 0.3s;
      display: flex;
      align-items: center;
      justify-content: center;
      flex: 1;
      min-width: 120px;
    }

    .record-btn {
      background: #333;
      color: white;
    }

    .human-btn {
      background: #28a745;
      color: white;
    }

    .video-btn {
      background: #007bff;
      color: white;
    }

    .record-btn:disabled,
    .human-btn:disabled,
    .video-btn:disabled {
      background: #666;
      cursor: not-allowed;
    }

    .spinner {
      width: 16px;
      height: 16px;
      margin-left: 10px;
      border: 2px solid white;
      border-top: 2px solid transparent;
      border-radius: 50%;
      animation: spin 1s linear infinite;
    }

    @keyframes spin {
      to {
        transform: rotate(360deg);
      }
    }

    .video-container {
      display: none;
      position: fixed;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      background: rgba(0, 0, 0, 0.9);
      z-index: 1000;
      flex-direction: column;
      align-items: center;
      justify-content: center;
    }

    .video-container.active {
      display: flex;
    }

    .video-grid {
      display: flex;
      gap: 20px;
      margin-bottom: 20px;
    }

    .video-box {
      background: #333;
      border-radius: 10px;
      overflow: hidden;
      position: relative;
    }

    .local-video {
      width: 300px;
      height: 225px;
    }

    .remote-video {
      width: 600px;
      height: 450px;
    }

    .video-box video {
      width: 100%;
      height: 100%;
      object-fit: cover;
    }

    .video-label {
      position: absolute;
      bottom: 10px;
      left: 10px;
      background: rgba(0, 0, 0, 0.7);
      color: white;
      padding: 5px 10px;
      border-radius: 5px;
      font-size: 12px;
    }

    .video-controls {
      display: flex;
      gap: 10px;
    }

    .video-controls button {
      padding: 12px 20px;
      border: none;
      border-radius: 8px;
      cursor: pointer;
      font-size: 14px;
      transition: background 0.3s;
    }

    .end-call {
      background: #dc3545;
      color: white;
    }

    .toggle-video,
    .toggle-audio {
      background: #6c757d;
      color: white;
    }

    .connection-status {
      margin-bottom: 10px;
      padding: 10px;
      border-radius: 5px;
      text-align: center;
      font-weight: bold;
    }

    .connecting {
      background: #fff3cd;
      color: #856404;
    }

    .connected {
      background: #d4edda;
      color: #155724;
    }

    .disconnected {
      background: #f8d7da;
      color: #721c24;
    }
  </style>
</head>

<body>

  <div class="container">
    <model-viewer id="avatar" src="https://raw.githubusercontent.com/mehdiyevsss/glb-assets/main/brunette.glb" autoplay
      camera-controls interaction-prompt="none" style="--poster-color: transparent;">
    </model-viewer>

    <div class="chat-section">
      <div class="messages" id="messages"></div>
      <div class="controls">
        <button id="recordBtn" class="record-btn">üéôÔ∏è Record</button>
        <button id="humanBtn" class="human-btn" style="display: none;">üë• Connect to Human</button>
      </div>
    </div>
  </div>

  <!-- Video Call Container -->
  <div class="video-container" id="videoContainer">
    <div class="connection-status" id="connectionStatus">Connecting to operator...</div>
    <div class="video-grid">
      <div class="video-box local-video">
        <video id="localVideo" autoplay muted></video>
        <div class="video-label">You</div>
      </div>
      <div class="video-box remote-video">
        <video id="remoteVideo" autoplay></video>
        <div class="video-label">Operator</div>
      </div>
    </div>
    <div class="video-controls">
      <button id="toggleVideo" class="toggle-video">üìπ Video On</button>
      <button id="toggleAudio" class="toggle-audio">üé§ Audio On</button>
      <button id="endCall" class="end-call">üìû End Call</button>
    </div>
  </div>

  <script type="module" src="https://unpkg.com/@google/model-viewer/dist/model-viewer.min.js"></script>

  <script>
    const recordBtn = document.getElementById("recordBtn");
    const humanBtn = document.getElementById("humanBtn");
    const messagesEl = document.getElementById("messages");
    const avatar = document.querySelector("#avatar");
    const videoContainer = document.getElementById("videoContainer");
    const connectionStatus = document.getElementById("connectionStatus");
    const localVideo = document.getElementById("localVideo");
    const remoteVideo = document.getElementById("remoteVideo");
    const toggleVideoBtn = document.getElementById("toggleVideo");
    const toggleAudioBtn = document.getElementById("toggleAudio");
    const endCallBtn = document.getElementById("endCall");

    let mediaRecorder, audioChunks = [];
    let audioCtx, analyser, micSource;
    let needsHumanOperator = false;

    // WebRTC variables
    let localStream;
    let peerConnection;
    let signalingSocket;
    let clientId = generateUUID();
    let isVideoEnabled = true;
    let isAudioEnabled = true;

    function generateUUID() {
      return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function (c) {
        var r = Math.random() * 16 | 0, v = c == 'x' ? r : (r & 0x3 | 0x8);
        return v.toString(16);
      });
    }

    recordBtn.onclick = async () => {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

      audioChunks = [];
      mediaRecorder = new MediaRecorder(stream);
      mediaRecorder.ondataavailable = e => audioChunks.push(e.data);
      mediaRecorder.onstop = () => processRecording();

      audioCtx = new AudioContext();
      micSource = audioCtx.createMediaStreamSource(stream);
      analyser = audioCtx.createAnalyser();
      micSource.connect(analyser);
      detectSilence();

      showLoading(true);
      mediaRecorder.start();
    };

    humanBtn.onclick = () => {
      initializeVideoCall();
    };

    function detectSilence(threshold = 0.01, timeout = 1500) {
      const data = new Uint8Array(analyser.fftSize);
      let lastActivity = Date.now();

      function loop() {
        analyser.getByteTimeDomainData(data);
        const isSilent = data.every(v => Math.abs(v - 128) < threshold * 128);

        if (!isSilent) lastActivity = Date.now();
        if (Date.now() - lastActivity > timeout && mediaRecorder.state === "recording") {
          mediaRecorder.stop();
        } else {
          requestAnimationFrame(loop);
        }
      }
      loop();
    }

    function showLoading(loading) {
      if (loading) {
        recordBtn.disabled = true;
        recordBtn.innerHTML = `Listening... <span class="spinner"></span>`;
      } else {
        recordBtn.disabled = false;
        recordBtn.textContent = "üéôÔ∏è Record";
      }
    }

    async function processRecording() {
      const audioBlob = new Blob(audioChunks, { type: "audio/mp3" });
      const formData = new FormData();
      formData.append("audio", audioBlob, "voice.mp3");

      const trans = await fetch("https://377e-2a02-810d-1810-9100-7032-5766-d185-f96.ngrok-free.app/transcribe", {
        method: "POST",
        body: formData
      }).then(res => res.json());

      addMessage("user", trans.transcript);

      const respForm = new FormData();
      respForm.append("text", trans.transcript);
      const resp = await fetch("https://377e-2a02-810d-1810-9100-7032-5766-d185-f96.ngrok-free.app/respond", {
        method: "POST",
        body: respForm
      }).then(res => res.json());

      addMessage("assistant", resp.response);

      // Check if human operator is needed
      if (resp.needs_human_operator) {
        needsHumanOperator = true;
        humanBtn.style.display = "block";
        addMessage("system", "I can connect you with a human operator for better assistance. Click the 'Connect to Human' button if you'd like to proceed.");
      }

      const audio = new Audio("https://377e-2a02-810d-1810-9100-7032-5766-d185-f96.ngrok-free.app" + resp.audio_url);
      audio.play();

      playAvatarMouth();
      showLoading(false);
    }

    function addMessage(role, text) {
      const div = document.createElement("div");
      div.className = `message ${role}`;
      div.textContent = text;
      messagesEl.appendChild(div);
      messagesEl.scrollTop = messagesEl.scrollHeight;
    }

    function playAvatarMouth() {
      avatar.animationName = "Talk";
      setTimeout(() => {
        avatar.animationName = "";
      }, 2000);
    }

    // WebRTC Functions
    const API_BASE = window.location.origin;
    const WS_BASE = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
    const WS_HOST = window.location.host;

    async function initializeVideoCall() {
      try {
        // Get user media
        localStream = await navigator.mediaDevices.getUserMedia({
          video: true,
          audio: true
        });
        localVideo.srcObject = localStream;

        // Show video container
        videoContainer.classList.add('active');

        // Initialize peer connection
        setupPeerConnection();

        // Connect to signaling server
        connectToSignalingServer();

        addMessage("system", "Connecting you to a human operator...");

      } catch (error) {
        console.error('Error accessing media devices:', error);
        addMessage("system", "Unable to access camera/microphone. Please check permissions.");
      }
    }

    function setupPeerConnection() {
      const configuration = {
        iceServers: [
          { urls: 'stun:stun.l.google.com:19302' },
          { urls: 'stun:stun1.l.google.com:19302' },
          { urls: 'stun:stun2.l.google.com:19302' }
        ]
      };

      peerConnection = new RTCPeerConnection(configuration);

      // Add local stream to peer connection
      localStream.getTracks().forEach(track => {
        peerConnection.addTrack(track, localStream);
        console.log('Added track to peer connection:', track.kind);
      });

      // Handle remote stream
      peerConnection.ontrack = (event) => {
        console.log('Received remote stream');
        remoteVideo.srcObject = event.streams[0];
        connectionStatus.textContent = "Connected to operator";
        connectionStatus.className = "connection-status connected";
      };

      // Handle ICE candidates
      peerConnection.onicecandidate = (event) => {
        if (event.candidate) {
          console.log('Sending ICE candidate');
          if (signalingSocket.readyState === WebSocket.OPEN) {
            signalingSocket.send(JSON.stringify({
              type: 'ice-candidate',
              candidate: event.candidate
            }));
          }
        }
      };

      peerConnection.onconnectionstatechange = () => {
        console.log('Connection state:', peerConnection.connectionState);
        const state = peerConnection.connectionState;

        if (state === 'connected') {
          connectionStatus.textContent = "Connected to operator";
          connectionStatus.className = "connection-status connected";
        } else if (state === 'disconnected' || state === 'failed') {
          connectionStatus.textContent = "Connection lost";
          connectionStatus.className = "connection-status disconnected";
          setTimeout(() => endVideoCall(), 2000);
        }
      };

      peerConnection.oniceconnectionstatechange = () => {
        console.log('ICE connection state:', peerConnection.iceConnectionState);
      };
    }

    function connectToSignalingServer() {
      const wsUrl = `${WS_BASE}//${WS_HOST}/ws/signaling/${clientId}/customer`;
      console.log('Connecting to:', wsUrl);

      signalingSocket = new WebSocket(wsUrl);

      signalingSocket.onopen = () => {
        console.log('Connected to signaling server');
        connectionStatus.textContent = "Waiting for operator...";
        connectionStatus.className = "connection-status connecting";
      };

      signalingSocket.onmessage = async (event) => {
        try {
          const message = JSON.parse(event.data);
          console.log('Received signaling message:', message.type);

          switch (message.type) {
            case 'matched':
              console.log('Matched with operator:', message.partner_id);
              connectionStatus.textContent = "Operator found! Establishing connection...";

              // Customer creates the offer
              try {
                const offer = await peerConnection.createOffer({
                  offerToReceiveAudio: true,
                  offerToReceiveVideo: true
                });
                await peerConnection.setLocalDescription(offer);

                console.log('Sending offer');
                signalingSocket.send(JSON.stringify({
                  type: 'offer',
                  offer: offer
                }));
              } catch (error) {
                console.error('Error creating offer:', error);
              }
              break;

            case 'answer':
              console.log('Received answer');
              try {
                await peerConnection.setRemoteDescription(message.answer);
              } catch (error) {
                console.error('Error setting remote description:', error);
              }
              break;

            case 'ice-candidate':
              console.log('Received ICE candidate');
              try {
                await peerConnection.addIceCandidate(message.candidate);
              } catch (error) {
                console.error('Error adding ICE candidate:', error);
              }
              break;

            case 'partner_disconnected':
              console.log('Operator disconnected');
              connectionStatus.textContent = "Operator disconnected";
              connectionStatus.className = "connection-status disconnected";
              setTimeout(() => endVideoCall(), 2000);
              break;
          }
        } catch (error) {
          console.error('Error handling signaling message:', error);
        }
      };

      signalingSocket.onclose = (event) => {
        console.log('Signaling connection closed:', event.code, event.reason);
        if (videoContainer.classList.contains('active')) {
          connectionStatus.textContent = "Connection lost";
          connectionStatus.className = "connection-status disconnected";
        }
      };

      signalingSocket.onerror = (error) => {
        console.error('Signaling WebSocket error:', error);
        connectionStatus.textContent = "Connection error";
        connectionStatus.className = "connection-status disconnected";
      };
    }

    // Video control event listeners
    toggleVideoBtn.onclick = () => {
      isVideoEnabled = !isVideoEnabled;
      localStream.getVideoTracks().forEach(track => {
        track.enabled = isVideoEnabled;
      });
      toggleVideoBtn.textContent = isVideoEnabled ? "üìπ Video On" : "üìπ Video Off";
    };

    toggleAudioBtn.onclick = () => {
      isAudioEnabled = !isAudioEnabled;
      localStream.getAudioTracks().forEach(track => {
        track.enabled = isAudioEnabled;
      });
      toggleAudioBtn.textContent = isAudioEnabled ? "üé§ Audio On" : "üé§ Audio Off";
    };

    endCallBtn.onclick = () => {
      endVideoCall();
    };

    function endVideoCall() {
      // Close peer connection
      if (peerConnection) {
        peerConnection.close();
        peerConnection = null;
      }

      // Close signaling connection
      if (signalingSocket && signalingSocket.readyState === WebSocket.OPEN) {
        signalingSocket.send(JSON.stringify({ type: 'disconnect' }));
        signalingSocket.close();
      }

      // Stop local stream
      if (localStream) {
        localStream.getTracks().forEach(track => track.stop());
        localStream = null;
      }

      // Hide video container
      videoContainer.classList.remove('active');

      // Reset UI
      humanBtn.style.display = "none";
      needsHumanOperator = false;

      addMessage("system", "Video call ended. You can continue chatting with the AI assistant.");
    }

    // Handle page unload
    window.addEventListener('beforeunload', () => {
      if (peerConnection || signalingSocket) {
        endVideoCall();
      }
    });
  </script>

</body>

</html>