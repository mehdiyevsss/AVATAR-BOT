<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Voice Avatar Chatbot</title>
  <style>
    /* Add your original styles here or keep as-is */
  </style>
</head>
<body>

<div class="container">
  <model-viewer id="avatar"
    src="https://raw.githubusercontent.com/mehdiyevsss/glb-assets/main/brunette.glb"
    autoplay camera-controls interaction-prompt="none"
    style="--poster-color: transparent;">
  </model-viewer>

  <div class="chat-section">
    <div class="messages" id="messages"></div>
    <button id="recordBtn" class="record-btn">üéôÔ∏è Record</button>
  </div>
</div>

<script type="module" src="https://unpkg.com/@google/model-viewer/dist/model-viewer.min.js"></script>
<script>
const recordBtn = document.getElementById("recordBtn");
const messagesEl = document.getElementById("messages");
const avatar = document.querySelector("#avatar");

let mediaRecorder, audioChunks = [];
let audioCtx, analyser, micSource;
let interruptAudio = false;
let currentAudio = null;

recordBtn.onclick = startRecording;

async function startRecording() {
  const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

  audioChunks = [];
  mediaRecorder = new MediaRecorder(stream);
  mediaRecorder.ondataavailable = e => audioChunks.push(e.data);
  mediaRecorder.onstop = () => processRecording();

  audioCtx = new AudioContext();
  micSource = audioCtx.createMediaStreamSource(stream);
  analyser = audioCtx.createAnalyser();
  micSource.connect(analyser);
  detectSilence();

  showLoading(true);
  mediaRecorder.start();

  monitorInterrupts(stream); // Start continuous monitoring
}

function detectSilence(threshold = 0.01, timeout = 1500) {
  const data = new Uint8Array(analyser.fftSize);
  let lastActivity = Date.now();

  function loop() {
    analyser.getByteTimeDomainData(data);
    const isSilent = data.every(v => Math.abs(v - 128) < threshold * 128);

    if (!isSilent) lastActivity = Date.now();
    if (Date.now() - lastActivity > timeout && mediaRecorder.state === "recording") {
      mediaRecorder.stop();
    } else {
      requestAnimationFrame(loop);
    }
  }
  loop();
}

function showLoading(loading) {
  recordBtn.disabled = loading;
  recordBtn.innerHTML = loading ? `Listening... <span class="spinner"></span>` : "üéôÔ∏è Record";
}

async function processRecording(forcedTranscript = null) {
  if (!forcedTranscript) {
    const audioBlob = new Blob(audioChunks, { type: "audio/mp3" });
    const formData = new FormData();
    formData.append("audio", audioBlob, "voice.mp3");

    const trans = await fetch("/transcribe", { method: "POST", body: formData })
      .then(res => res.json());
    forcedTranscript = trans.transcript;
  }

  addMessage("user", forcedTranscript);

  const respForm = new FormData();
  respForm.append("text", forcedTranscript);
  const resp = await fetch("/respond", { method: "POST", body: respForm })
    .then(res => res.json());

  addMessage("assistant", resp.response);

  const audio = new Audio(resp.audio_url);
  currentAudio = audio;
  audio.play();
  playAvatarMouth();

  audio.onended = () => {
    showLoading(false);
    startRecording();
  };
}

function addMessage(role, text) {
  const div = document.createElement("div");
  div.className = `message ${role}`;
  div.textContent = text;
  messagesEl.appendChild(div);
  messagesEl.scrollTop = messagesEl.scrollHeight;
}

function playAvatarMouth() {
  avatar.animationName = "Talk";
  setTimeout(() => { avatar.animationName = ""; }, 2000);
}

async function monitorInterrupts(stream) {
  const recorder = new MediaRecorder(stream);
  let chunks = [];

  recorder.ondataavailable = e => chunks.push(e.data);
  recorder.onstop = async () => {
    const formData = new FormData();
    formData.append("audio", new Blob(chunks, { type: "audio/mp3" }), "chunk.mp3");

    const result = await fetch("/listen_chunk", {
      method: "POST",
      body: formData
    }).then(r => r.json());

    if (result.interrupt && currentAudio) {
      currentAudio.pause();
      interruptAudio = true;
      showLoading(false);
      addMessage("user", result.command);
      processRecording(result.command);
    } else {
      if (!interruptAudio) setTimeout(() => monitorInterrupts(stream), 2500);
    }
  };

  recorder.start();
  setTimeout(() => recorder.stop(), 2500);
}
</script>

</body>
</html>
