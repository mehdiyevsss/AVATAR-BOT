<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Voice Avatar Chatbot</title>
  <style>
    * { box-sizing: border-box; }
    html, body {
      margin: 0;
      padding: 0;
      height: 100vh;
      width: 100vw;
      font-family: "Segoe UI", sans-serif;
      background: #1e1e1e;
      display: flex;
      justify-content: center;
      align-items: center;
    }

    .container {
      display: flex;
      height: 90vh;
      width: 90vw;
      max-width: 1400px;
      border-radius: 16px;
      background: #fff;
      box-shadow: 0 0 20px rgba(0, 0, 0, 0.25);
      overflow: hidden;
    }

    #avatar {
      flex: 1 1 0;
      height: 100%;
      background: url('/static/Swisscom.jpg') center center / cover no-repeat;
    }

    .chat-section {
      flex: 1 1 0;
      display: flex;
      flex-direction: column;
      padding: 20px;
      background: #f5f5f5;
      height: 100%;
    }

    .messages {
      flex: 1;
      overflow-y: auto;
      margin-bottom: 15px;
      padding-right: 10px;
      display: flex;
      flex-direction: column;
    }

    .message {
      margin-bottom: 10px;
      padding: 14px 18px;
      border-radius: 14px;
      font-size: 15px;
      max-width: 100%;
      background: #e0e0e0;
      color: #000;
    }

    .assistant {
      align-self: flex-start;
      background-color: #dbe4ff;
    }

    .user {
      align-self: flex-end;
      background-color: #ffe2e2;
    }

    .record-btn {
      padding: 14px;
      font-size: 16px;
      border-radius: 10px;
      border: none;
      background: #333;
      color: white;
      cursor: pointer;
      transition: background 0.3s;
      display: flex;
      align-items: center;
      justify-content: center;
    }

    .record-btn:disabled {
      background: #666;
    }

    .spinner {
      width: 16px;
      height: 16px;
      margin-left: 10px;
      border: 2px solid white;
      border-top: 2px solid transparent;
      border-radius: 50%;
      animation: spin 1s linear infinite;
    }

    @keyframes spin {
      to { transform: rotate(360deg); }
    }
  </style>

  <script type="importmap">
    {
      "imports": {
        "three": "https://cdn.jsdelivr.net/npm/three@0.170.0/build/three.module.js/+esm",
        "three/addons/": "https://cdn.jsdelivr.net/npm/three@0.170.0/examples/jsm/",
        "talkinghead": "https://cdn.jsdelivr.net/gh/met4citizen/TalkingHead@1.5/modules/talkinghead.mjs"
      }
    }
  </script>
</head>
<body>

<div class="container">
  <div id="avatar"></div>

  <div class="chat-section">
    <div class="messages" id="messages"></div>
    <button id="recordBtn" class="record-btn">ðŸŽ™ Record</button>
  </div>
</div>

<div id="loading" style="position: absolute; top: 10px; left: 10px; color: white; font-size: 18px;">Loading avatar...</div>

<script type="module">
import { TalkingHead } from "talkinghead";

let head, audioCtx, analyser, micSource, mediaRecorder, audioChunks = [];

const avatarContainer = document.getElementById("avatar");
const messagesEl = document.getElementById("messages");
const recordBtn = document.getElementById("recordBtn");

async function initAvatar() {
  head = new TalkingHead(avatarContainer, {
    ttsEndpoint: "none",
    lipsyncModules: ["en"],
    cameraView: "full"
  });

  await head.showAvatar({
    url: '/static/brunette.glb',
    body: 'F',
    avatarMood: 'neutral',
    lipsyncLang: 'en'
  }, ev => {
    if (ev.lengthComputable) {
      document.getElementById("loading").textContent = `Loading ${Math.round(ev.loaded / ev.total * 100)}%`;
    }
  });

  document.getElementById("loading").style.display = "none";
}

recordBtn.onclick = async () => {
  const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

  audioChunks = [];
  mediaRecorder = new MediaRecorder(stream);
  mediaRecorder.ondataavailable = e => audioChunks.push(e.data);
  mediaRecorder.onstop = () => processRecording();

  audioCtx = new AudioContext();
  micSource = audioCtx.createMediaStreamSource(stream);
  analyser = audioCtx.createAnalyser();
  micSource.connect(analyser);
  detectSilence();

  showLoading(true);
  mediaRecorder.start();
};

function detectSilence(threshold = 0.01, timeout = 1500) {
  const data = new Uint8Array(analyser.fftSize);
  let lastActivity = Date.now();

  function loop() {
    analyser.getByteTimeDomainData(data);
    const isSilent = data.every(v => Math.abs(v - 128) < threshold * 128);

    if (!isSilent) lastActivity = Date.now();
    if (Date.now() - lastActivity > timeout && mediaRecorder.state === "recording") {
      mediaRecorder.stop();
    } else {
      requestAnimationFrame(loop);
    }
  }
  loop();
}

function showLoading(loading) {
  if (loading) {
    recordBtn.disabled = true;
    recordBtn.innerHTML = `Listening... <span class="spinner"></span>`;
  } else {
    recordBtn.disabled = false;
    recordBtn.textContent = "ðŸŽ™ Record";
  }
}

function addMessage(role, text) {
  const div = document.createElement("div");
  div.className = `message ${role}`;
  div.textContent = text;
  messagesEl.appendChild(div);
  messagesEl.scrollTop = messagesEl.scrollHeight;
}


async function processRecording() {
  const audioBlob = new Blob(audioChunks, { type: "audio/mp3" });
  const formData = new FormData();
  formData.append("audio", audioBlob, "voice.mp3");

  const trans = await fetch("http://localhost:8000/transcribe", {
    method: "POST",
    body: formData
  }).then(res => res.json());

  addMessage("user", trans.transcript);

  const respForm = new FormData();
  respForm.append("text", trans.transcript);
  const resp = await fetch("http://localhost:8000/respond", {
    method: "POST",
    body: respForm
  }).then(res => res.json());

  addMessage("assistant", resp.response);

  const audioURL = "http://localhost:8000" + resp.audio_url;
  const blob = await fetch(audioURL).then(r => r.blob());
  const buffer = await blob.arrayBuffer();
  const decoded = await head.audioCtx.decodeAudioData(buffer);

  const whisperResp = await fetch("https://api.openai.com/v1/audio/transcriptions", {
    method: "POST",
    body: (() => {
      const f = new FormData();
      f.append("file", new File([blob], "tts.mp3", { type: "audio/mpeg" }));
      f.append("model", "whisper-1");
      f.append("language", "en");
      f.append("response_format", "verbose_json");
      f.append("prompt", "[The following is a full verbatim transcription without additional details, comments or emojis:]");
      f.append("timestamp_granularities[]", "word");
      return f;
    })(),
    headers: {
      "Authorization": "Bearer PLACE_THE_API_HERE" 
    }
  });

  const json = await whisperResp.json();

  const timed = {
    audio: decoded,
    words: [],
    wtimes: [],
    wdurations: [],
    markers: [],
    mtimes: []
  };

  json.words.forEach(w => {
    timed.words.push(w.word);
    timed.wtimes.push(w.start * 1000 - 150);
    timed.wdurations.push((w.end - w.start) * 1000);
  });

  head.speakAudio(timed);
  showLoading(false);
}

initAvatar();
</script>

</body>
</html>